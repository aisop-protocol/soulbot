# Telegram Bot Token
TELEGRAM_BOT_TOKEN=your_telegram_bot_token_here

# AI Provider Configuration (CLI Mode)
OPENCODE_CLI=true
CLAUDE_CLI=false
# GEMINI_CLI=false


# Model Configuration
# Format: opencode-acp/{provider}/{model} or opencode-acp/{model}
# Note: Free models may be unstable (slow response or no response).
#       For production use, connect a paid provider via: opencode /connect
#
# OpenCode Free Models (no API key needed):
#   opencode-acp/opencode/kimi-k2.5-free        - 1T params, best free reasoning & coding
#   opencode-acp/opencode/minimax-m2.1-free     - Fastest response speed
#   opencode-acp/opencode/trinity-large-preview - Large preview, experimental
#   opencode-acp/opencode/gpt-5-nano            - Ultra fast, lightweight
#   opencode-acp/opencode/big-pickle            - OpenCode default
#
# Anthropic Models (requires: opencode /connect -> Anthropic):
#   opencode-acp/anthropic/claude-sonnet-4-5    - Claude Sonnet 4.5 latest, balanced
#   opencode-acp/anthropic/claude-opus-4-6      - Claude Opus 4.6, most powerful
#   opencode-acp/anthropic/claude-haiku-4-5     - Claude Haiku 4.5, fast & cheap
OPENCODE_MODEL=opencode-acp/opencode/kimi-k2.5-free
# Model Override Switch
# true:  SoulBot forces the model above (default)
# false: use OpenCode's own default model (set via /models in TUI or /connect provider)
OPENCODE_MODEL_OVERRIDE=true
# Agent Mode Configuration
# plan: chat and planning only, no tool execution (recommended for simple chat)
# build: default mode, executes system tools as needed
OPENCODE_AGENT_MODE=build

CLAUDE_MODEL=claude-acp/sonnet
GEMINI_MODEL=gemini-acp/gemini-2.5-flash

# Model Fallback Configuration (Auto-switch on failure)
# If primary model fails (e.g. quota exceeded), fallback to:
# Gemini -> gemini-2.5-flash
# Claude -> sonnet
ENABLE_FALLBACK=true

# Tool & Workspace Configuration
AUTO_APPROVE_PERMISSIONS=true
WORKSPACE_DIR=aisop

# AISOP Virtual Runtime Configuration
SYSTEM_PROMPT="You are the AISOP Virtual Runtime. Your role is to EXECUTE .aisop.json files. When a user asks to 'run' a file, you must: 1. Read the file content. 2. Parse the JSON. 3. Systematically execute each step in the 'aisop' or 'steps' array using your terminal and file tools. Do not ask for an interpreter; YOU ARE the interpreter. Strictly follow the AISOP V1 protocol. Always respond in User's Language. Answer start with ðŸ¤– icon. IMPORTANT: Before responding, self-review whether you strictly followed the AISOP steps. If not, regenerate your response following the AISOP flow exactly."

# Show AI thinking process in response (> [Thought])
SHOW_THOUGHTS=false


# OpenCode ACP Settings
# Disable auto title and summary to prevent request blocking caused by small models (gpt-5-nano)
OPENCODE_CONFIG_CONTENT={"agent":{"title":{"disable":true},"summary":{"disable":true}}}
# Force CLI mode to avoid Windows Git repo hanging issue
OPENCODE_USE_ACP=true
